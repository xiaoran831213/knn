%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation LaTeX Template Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License: CC BY-NC-SA 3.0
% (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ----------------------------------------------------------------------------------------
% PACKAGES AND THEMES
% ----------------------------------------------------------------------------------------

\documentclass{beamer}

\mode<presentation> {

  % The Beamer class comes with a number of default slide themes which
  % change the colors and layouts of slides. Below this is a list of
  % all the themes, uncomment each in turn to see what they look like.

  % \usetheme{default} \usetheme{AnnArbor} \usetheme{Antibes}
  % \usetheme{Bergen} \usetheme{Berkeley} \usetheme{Berlin}
  % \usetheme{Boadilla} \usetheme{CambridgeUS} \usetheme{Copenhagen}
  % \usetheme{Darmstadt} \usetheme{Dresden} \usetheme{Frankfurt}
  % \usetheme{Goettingen} \usetheme{Hannover} \usetheme{Ilmenau}
  % \usetheme{JuanLesPins} \usetheme{Luebeck}
  \usetheme{Madrid}
  % \usetheme{Malmoe} \usetheme{Marburg} \usetheme{Montpellier}
  % \usetheme{PaloAlto} \usetheme{Pittsburgh} \usetheme{Rochester}
  % \usetheme{Singapore} \usetheme{Szeged} \usetheme{Warsaw}

  % As well as themes, the Beamer class has a number of color themes
  % for any slide theme. Uncomment each of these in turn to see how it
  % changes the colors of your current slide theme.

  % \usecolortheme{albatross}
  \usecolortheme{beaver}
  % \usecolortheme{beetle} \usecolortheme{crane}
  % \usecolortheme{dolphin} \usecolortheme{dove} \usecolortheme{fly}
  % \usecolortheme{lily} \usecolortheme{orchid} \usecolortheme{rose}
  % \usecolortheme{seagull} \usecolortheme{seahorse}
  % \usecolortheme{whale} \usecolortheme{wolverine}

  % \setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
  % \setbeamertemplate{footline}[page
  % number] % To replace the footer line in all slides with a simple slide count uncomment this line

  % \setbeamertemplate{navigation
  % symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}
\include{xtong}
\newcommand{\xmx}{\bs{X}} \newcommand{\xmt}{\bs{X}^{\prime}}
\newcommand{\imx}{\bs{I}} \newcommand{\umx}{\bs{U}}
\newcommand{\umt}{\bs{U}^{\prime}} \newcommand{\yvc}{\bs{y}}
\newcommand{\yht}{\hat{\bs{y}}}
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables

% ----------------------------------------------------------------------------------------
% TITLE PAGE
% ----------------------------------------------------------------------------------------

\title[Kernel Genomics]{Meta analysis of Variance Components \\
  simulation study}

\author{Xiaoran Tong} % Your name
\institute[EPI Biosta,
MSU] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{ Michigan State University \\ % Your institution for the title page
  \medskip \textit{tongxia1@msu.edu} \\% Your email address
  \textit{qlu@epi.msu.edu} % Your email address
} \date{\today} % Date, can be changed to a custom date

\begin{document}

\begin{frame}
  \titlepage % Print the title page as the first slide
\end{frame}

\begin{frame}
  \frametitle{Table of
    Content} % Table of contents slide, comment this block out to remove it
  \tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}

% ----------------------------------------------------------------------------------------
% PRESENTATION SLIDES
% ----------------------------------------------------------------------------------------
\section{Introduction}
% ----------------------------------------------------------------------------------------
\begin{frame}
  \frametitle{Introduction} %
  \textbf{Variance Component Model (VCM):} \\
  are suitable to depict the influence of ultra high dimentional $\xx$
  on $\vy$, with an typical construct of
  \begin{align}\label{eq:vcm}
    h(\vy) \sim \mathcal{N}(0, \xv), \quad
    \xv = \xv_{\bs{e}} + \xv_{\xx} = \sigma^2_0 \id + \sum_{i=1}^L
    \sigma^2_i \mathcal{K}_i(\xx)
  \end{align}
  \begin{itemize}
  \item $h$ transform $\vy$ into a sample following multivariate
    normrl (MVN) of mean $\bs{0}^N$ and covariance $\xv^{N \times N}$;
  \item $\xv$ is determined partially by $\xx$ through $L$ kernels:
    $\{\mathcal{K}_{1 \dots L}\}$, while the rest is left to an white
    noise $\id$;
  \item kernels are weighted by the to be fitted \textbf{variance
      component (VC)}
    $\vtheta = \{\sigma^2_0, \sigma^2_1 \dots \sigma^2_L\}$.
  \end{itemize}
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}
  Despite being able to handle problems of ultra dimensionality, \\
  \textbf{VCM has its own issues}:
  \begin{itemize}
  \item large sample is required to stable a VCM;
  \item inevitable $O(N^3)$ matrix inversion;
  \item heterogeneous effect of $\xx$ when many variants are involved.
  \end{itemize}
  \textbf{Which motivate the meta-analysis based on VCM (MVCM)}:
  \begin{itemize}
  \item pooling large sample;
  \item distributed analytical load;
  \item model aggregation to counter heterogeneity;
  \end{itemize}
\end{frame}
% ----------------------------------------------------------------------------------------
\section{Meta-VCM}
\begin{frame}\frametitle{meta-VCM procedure}
  Let $\vc_i=(\vy_i, \xx_i)$ denote the i th. participating cohort; \\
  \textbf{{\color{red}meta}-analysis:}
  \begin{itemize}
  \item $\xc = \{\vc_1, \dots, \vc_Q \}$, $Q$ cohorts joined the consortium;
  \item $\hat{\vtheta}=\{\hat{\vtheta}_1, \dots, \hat{\vtheta}_Q\}$, develop Q models;
  \item $\hat{\vtheta} = \frac{\sum_i^Q \vw_i
      \hat{\vtheta}_i}{\sum_i^S \vw_i}$, weighted model aggregation
  \end{itemize}
  \textbf{{\color{red}mega}-analysis:}
  \begin{itemize}
  \item develop 1 model with the entire consortium;
  \item (included here as reference.)
  \end{itemize}
\end{frame}
% ----------------------------------------------------------------------------------------
\newcommand{\se}[1]{\hat{\mathtt{se}}\left(#1\right)}
\newcommand{\ti}{{\tilde{i}}}
\newcommand{\ef}{{\mathtt{o}}}
\begin{frame}\frametitle{weight scheme}
  Let $i = 1 \dots Q$ index the cohorts, $j = 1 \dots L$ index the VC(s).\\
  \textbf{weight by confidence:}
  \begin{align}
    w_{i,j} &= \frac{\left[\se{\theta_{i,j}} \right ]^2}
    {\sum_\ti \left[\se{\theta_{\ti,j}} \right ]^2} \\
    w_{i,j} &= \frac{n_i}{\sum_\ti n_\ti}
  \end{align}
  {\color{blue}\textbf{no extra analysis required}}
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}\frametitle{weight scheme, continued}
  \textbf{weight by relative validity:}
  \begin{align}
    \gamma_i &= \frac{\sum_{r \in i^-}{\ef( \vc_i; \vtheta_r)}}
    {\ef(\vc_i; \vtheta_i)} \\
    w_{i,j}  &= \frac{\gamma_i}{\sum_\ti \gamma_\ti}
  \end{align}
  the function $\ef(\vc;\vtheta)$ tells in standard space how well
  model $\vtheta$ fits cohort $\vc$, e.g., the geometric mean
  likelihood
  \begin{align}
    o_\mathtt{GML}(\vc; \vtheta) = \sqrt[n]{\mathcal{N}(\bs{0}, \xv_{\vc, \vtheta})}
  \end{align}
  {\color{red}\textbf{dilemma: some party have to compute $o(\vc; \vtheta)$}}
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}\frametitle{information completness}
  An meta-analysis does not cover all sample pairs in its kernel, an
  mega-analysis does.
  \begin{figure}
    \centering
    \includegraphics[width=.9\textwidth]{img/meta-mega}
    \caption{infomration completeness}
    \label{fig:info_comp}
  \end{figure}
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}\frametitle{logistical concerns}
  \begin{table}[h]
    \label{tb:cost}
    \begin{tabular}{|l|l|l|l|}
      \hline
      \textbf{actions}       & \textbf{meta} & \textbf{mix}  & \textbf{mega} \\ \hline
      client prepare kernels & $O(n^2PL)$    & $O(n^2PL)$    & no            \\ \hline
      client fit VCM         & $O(n^3C)$     & no            & no            \\ \hline
      client validate VCM(s) & $O(n^3Q)$     & no            & no            \\ \hline
      server prepare kernels & no            & no            & $O(n^2Q^2PL)$ \\ \hline
      server fit VCM         & no            & $O(n^3CQ)$    & $O(n^3Q^3C)$  \\ \hline
      server validate VCM(s) & no            & $O(n^3Q^2)$   & no            \\ \hline
    \end{tabular}
    \caption{computation required}
  \end{table}
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}\frametitle{logistical concerns, continue}
  \begin{table}[h]
    \label{tb:trust}
    \begin{tabular}{|l|c|c|c|}
      \hline
      \textbf{actions}        & \textbf{meta} & \textbf{mix}  & \textbf{maga} \\ \hline
      client prepare kernels  & no            & no            &               \\ \hline
      client fit VCM          & no            &               &               \\ \hline
      client validate VCM(s)  & no            &               &               \\ \hline
      server prepare kernels  &               &               & high          \\ \hline
      server fit VCM          &               & moderate      & moderate      \\ \hline
      server validate VCM(s)  &               & moderate      & moderate      \\ \hline
    \end{tabular}
    \caption{trust required}
  \end{table}
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}\frametitle{logistical concerns, continue}
  \begin{table}[]
    \begin{tabular}{|l|c|c|c|}
      \hline
      \textbf{action}        & \textbf{meta} & \textbf{mix} & \textbf{maga} \\ \hline
      client prepare kernels & low           & low          &               \\ \hline
      client fit VCM         & low           &              &               \\ \hline
      client validate VCM    & high          &              &               \\ \hline
      server prepare kernels &               &              & no            \\ \hline
      server fit VCM         &               & no           & no            \\ \hline
      server validate VCM    &               & no           & no            \\ \hline
    \end{tabular}
    \caption{incentive required}
  \end{table}
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}
  \begin{itemize}\frametitle{logistical concern, summarize}
  \item meta-analysis:
    \begin{itemize}
    \item least resource, almost no server involvement;
    \item rely on volunteerism to run validation test;
    \end{itemize}
  \item maga-analysis
    \begin{itemize}
    \item completness of information
    \item server should be $Q^2$ more powerful than an average client
    \item require enormous trust with raw data.
    \end{itemize}
  \item mixed-analysis
    \begin{itemize}
    \item validation analysis is readily applicable.
    \item have to trust the server with ``encrypted'' data.
    \end{itemize}
  \end{itemize}
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}\frametitle{access model validity}
  A VCM
  $\hat{\vtheta}=\{\hat{\sigma}^2_0, \hat{\sigma}^2_1 \dots
  \hat{\sigma}^2_L\}$ so developed must strive to generalize better on
  new data $(\vy, \xx)$, gauged by the following criteria:
  \begin{block}{\textbf{MNL}: mean negative log likelihood}
    $\mathtt{MNL}(\vy, \xx; \hat{\vtheta}) = \frac{1}{n}
    [\frac{1}{2}\vy\xvh^{-1}\vy + \frac{1}{2}\log{|\xvh|} +
    \frac{n}{2}\log{2\pi}]$
  \end{block}
  \begin{block}{\textbf{MSE}: mean squre error}
    $\mathtt{MSE}(\vy, \xx; \hat{\vtheta}) = \frac{\sigma_0^4}{n}
    \vy^T\hat{\xv}^{-1} \hat{\xv}^{-1}\vy$
  \end{block}
  where,
  $\xvh = \xvh_e + \xvh_\vx = \hat{\sigma}^2_0\id +
  \sum_{i=1}^L\hat{\sigma}_i^2 \mathcal{K}_i(\xx)$ are covariance
  composed from the new data by the meta-VCM $\hat{\vtheta}$; $n$
  is the size of new data.
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}\frametitle{simulation study}
  Validity of an Meta-VCM developed on $4$ cohorts, tested on a hold
  out cohort; data generated with a Gaussian kernel and polynomial
  kernels up to
  the 2nd order; \\
  \begin{figure}
    \raggedright  \scriptsize
    \begin{itemize}
    \item left to right: increase of inter-cohort heterogeneity;\\
    \item top to bottom: generalization error (top:MNL, bottom:MSE);
    \end{itemize}
    \normalsize
    \includegraphics[width=\linewidth]{km2_mnq_s01.png}
  \end{figure}
  \textbf{Information completeness is not necessarily an advantage when
  client cohorts are not homogeneous.}
\end{frame}
% ----------------------------------------------------------------------------------------
\section{Client Analysis}
\begin{frame}\frametitle{Client Analysis}
  \textbf{Improved VCM package can ease the participation} \\
  \begin{itemize}
  \item \textbf{use expanded MINQUE for speed:}
    \begin{itemize}
    \item directly solve $\vtheta$ instead of iterative search;
    \item easily expanded to improve fit;
    \end{itemize}
  \item the meta analysis paradim applied to one client
    \begin{itemize}
    \item 
    \end{itemize}
  \end{itemize}
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}\frametitle{meta-analysis as batch-analysis}
  Let $\vb_{ij}=(\vy_{ij}, \xx_{ij})$ denote the $j$ th partition of the $i$ th cohort; \\
  \textbf{batch-analysis:}
  \begin{itemize}
  \item $\vc_i = [\vb_{i1}^T, \dots, \vb_{iR}^T ]^T$, $R$ batches form a cohort;
  \item $\hat{\vtheta}=\{\hat{\vtheta}_1, \dots, \hat{\vtheta}_R\}$, analyse for R estimates;
  \item Repeat for $S$ times;
  \item $\hat{\vtheta} = \frac{\sum_i^{R \times S} w_i \hat{\vtheta}_i}{\sum_i^{R \times S} w_i}$, aggregate
  \end{itemize}
  \textbf{standard analysis:}
  \begin{itemize}
  \item get 1 estimate $\hat{\vtheta}$ for the entire cohort;
  \end{itemize}
\end{frame}
% ----------------------------------------------------------------------------------------
\begin{frame}\frametitle{meta-analysis as batch-analysis}
  \textbf{meta-analysis in common sense = batch-analysis of consortium}
  \begin{align*}
    \vb_{ij} & \in & \vc_i  & \in & \xc \\
    batch    & \qquad(stack)\to & cohort & \qquad(stack)\to & consortium
  \end{align*}
  \textbf{meta-analysis of a cohort = batch-analysis in common sense} \\
  treating a large, high dimensional cohort as an consortium inherits the benefits of a mata-analysis
  in common sense: \\
  \begin{itemize}
  \item computation reduced and easily distributed; 
  \item robust against within cohort heterogeneity.
  \end{itemize}
\end{frame}
% ----------------------------------------------------------------------------------------
\section{Simulations}
\begin{frame}
  \frametitle{Simulation Settings:} \textbf{Genomic Data Source
    $\xx$:}
  \begin{itemize}
  \item Drawn from 1000 Genome Project (total sample size is 2504);
  \item $P=3000$ SNP (MAF $> 0.01$) from a segment of chrosome 3.
  \item $N=500$ per cohort;
  \item $Q=4$ developing cohorts, $R=1$ evaluation cohort;
  \end{itemize}
  \textbf{Functional variants $\xx$:}
  \begin{itemize}
  \item $f = 0.1$, the fraction of functional SNPs;
  \item $\xx = (\one\vm^T) \odot \xg, \quad \vm \sim \mathcal{B}^P(f)$
  \item $\xx$ is the function part of genome data $\xg$
  \item $\vm$ is a vector mask of funtional variants
  \item $\mathcal{B}^P(f)$: $P$ Bernoulli experiments of success rate
    $f$.
  \end{itemize}
\end{frame}
% ---------------------------------------------------------
\begin{frame}
  \frametitle{Simulation Settings:}%
  \textbf{Response Generation: homogeneous effect}
  \begin{itemize}
  \item
    $ \vz_h \sim \mathcal{N}(\bs{0}, \sigma^2_0 \id + \sum_{i=1}^L
    \sigma_i^2 \mathcal{K}_i(\xx))$
  \item up to 3 kernels built from $\xx$:
    \begin{itemize}
    \item Normalized Gaussian:
      \begin{align}
        k(\vx, \vx^\prime)= \exp{[\frac{1}{2Pf}{\norm{\vx, \vx^\prime}_2^2}]}
      \end{align}
    \item Normalized Polynomial up to the 2nd order:
      \begin{align}
        \mathcal{K}(\xx, q)=(\frac{1}{Pf}\xx\xx^T)^q, \quad q={1, 2}
      \end{align}
    \end{itemize}
  \item variance components:
    \begin{align*}
      \sigma_0^2 = 0.1; \quad \sigma^2_i \sim \chi^2_2, \quad i = 1 \dots L
    \end{align*}
  \end{itemize}
\end{frame}
% ---------------------------------------------------------
\begin{frame}
  \frametitle{Simulation Settings:} %
  \textbf{Response Generation: heterogeneous effect}:\\
  \begin{itemize}
  \item the variance components varies across the $Q$ cohorts.
  \item the white noise and type of kernel is unchanged
    \begin{align*}
      \vz_j & \sim \mathcal{N}(\bs{0}, \sigma^2_0 \id + \sum_{i=1}^L
              \sigma_{i,j}^2 \mathcal{K}_i(\xx_j)), \quad
              \sigma_{i,j}^2 \sim \chi_2^2, \quad
              j = 1 \dots Q
    \end{align*}
  \item the total effect $\vz$ is a mix between the homogeneous and
    the cohort specifit heterogeneous effect.
  \end{itemize}
  \begin{align*}
    \vz & = \vz_h (1-\alpha) + [\vz_1^T, \dots, \vz_Q^T]^T \alpha,
          \quad \alpha \in [0, 1]
  \end{align*}
  Gradually increase the ratio of heterogeneity $alpha$ from 0 (fully
  homogeneous) to 1 (fully heterogeneous).
\end{frame}
\begin{frame}
  Generating heterogeneous effect:
  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{kma_sim_1kg.png}
  \end{figure}
\end{frame}
% ---------------------------------------------------------
\begin{frame}
  \frametitle{Simulation Settings:} %
  \textbf{Response Generation: Transformation on $\vy$:}
  \begin{itemize}
  \item the inverse transformation $g=h^{-1}$ is applied:
    $\vy=g(\vz)$.
  \item $g$ can be a distribution morph:
    \begin{itemize}
    \item normal $\bs{z}$ morph to student $t_{10}$ for outliers;
    \item normal $\bs{z}$ morph to $\mathcal{B}(p)$ for discretion;
    \end{itemize}
    derive the probability $p_*$ of $z_*$ either empirically, or from
    the diagnal of combined covariance; \\
    search $p_*$ in the quantile table of the target distribution for
    morphed value $y_*$;
  \item $g$ can also be a direct transform, for example:
    $$ y_* = \mathtt{sigmoid}(z_*), \quad \mathtt{or} \quad y_* = \mathtt{sin}(2\pi z_*) $$
  \end{itemize}
\end{frame}
% ---------------------------------------------------------% ---------------------------------------------------------
\begin{frame}
  \frametitle{Simulation Settings:} %
  \textbf{Training:}
  \begin{itemize}
  \item working model: normalized polynomial up to the 2nd order built
    from all variants $\xg$
    \begin{align}\label{eq:dvp}
      \xvh = \xvh_e + \xvh_\xg = \hat{\sigma}^2_0\id +
      \hat{\sigma}_1^2 (\frac{1}{P}{\xg \xg^T}) + \hat{\sigma}_2^2
      (\frac{1}{P}{\xg \xg^T})^2
    \end{align}
  \item for each cohort, use non-batched MINQUE for simplicity;
  \item pooling strategies:
    \begin{itemize}
    \item meta-analysis: aggregation of $Q$ sub-models
    \item mega-analysis: one model derived from the entire
      $N \times Q$ data
    \item average analyse: apply each sub-model to the testing data,
      get average performance, this is actually a non-pooling, but
      included for benchmark purpose.
    \end{itemize}
  \end{itemize}
\end{frame}
% ---------------------------------------------------------
\begin{frame}
  \frametitle{Simulation Settings:} %
  \textbf{Testing Performance} \\
  Let $(\vy, \xg)$ denote the testing cohort. First make a prediction
  of $\vyh$ assuming it is normal, even for MINQUE:
  \begin{align}
    \begin{split}
      \vyh &= \xvh_\xg \xvh^{-1} \vy,
    \end{split}
  \end{align}
  where $\xvh_\xg$ and $\xvh$ take the same form of (\ref{eq:dvp}).\\
  \textbf{Use the following performance criteria}
  \begin{itemize}
  \item $\mathtt{MSE} = \frac{1}{N} \norm{\vy, \hat{\vy}}_2^2 = \frac{1}{N} (\vy-\vyh)^T(\vy-\vyh)$
  \item
    $\mathtt{MNL} = \frac{1}{N} [\frac{1}{2}\vy\xvh^{-1}\vy +
    \frac{1}{2}\log{|\xvh|} + \frac{N}{2}\log{2\pi}]$
  \end{itemize}
\end{frame}
%---------------------------------------------------------
\section{Simulation Results}
% ---------------------------------------------------------
\begin{frame}{EXP 01: Use MINQUE, NLK plotted}
  \scriptsize super plot, left to right: gradual increase of heterogeneity;\\
  top: response is normal; bottom: response morphed into $t_{10}$ \\
  \normalsize
  \begin{figure}
    \includegraphics[width=\linewidth]{km2_mnq_s01.png} \\
    \includegraphics[width=\linewidth]{km2_mnq_s02.png}
  \end{figure}
  \tiny sub plot, left to right, avg: average performance without pooling;\\
  nlk and ssz: meta-analysis, model pooled by liklihood or sample size; \\
  whl: mega-analysis, model trained from the whole sample;
\end{frame}
% ---------------------------------------------------------
\section{Speculation}
\begin{frame}
  \frametitle{Speculation}
  \begin{itemize}
  \item increased inter-cohort heterogeneity cost the generalization
    of models built from mega-analyis.
  \item meta-analysis is robust to such heterogeneity.
  \item mana-analysis only suits for fully homogeneous populations.
  \item even without pooling of models (meta) or data (mega), the
    averge performance of sub-models are almost stable across levels
    of heterogeneity, showing the effect of a bagging assemble.
  \end{itemize}
\end{frame}
% ---------------------------------------------------------
\end{document}
